# üîß INSTRUCCIONES PARA DEBUGGEAR Y SOLUCIONAR FACE DETECTION

## üìä Resumen del Problema

Los logs muestran:
- ‚úÖ Frontend env√≠a frames al ML Service correctamente
- ‚úÖ ML Service recibe las solicitudes
- ‚ùå **PERO nunca detecta rostros** (`face=False` SIEMPRE)

**Root cause probable**: MediaPipe FaceMesh no se inicializ√≥ correctamente en Render, O las im√°genes que llegan est√°n vac√≠as/negras.

---

## üéØ Pr√≥ximos Pasos - Qu√© Hacer Ahora

### PASO 1: Esperar Redeployment de Render
El ML Service se est√° redeploys ahora con logging mejorado.
- **Tiempo**: ~3-5 minutos
- Ver status en: https://dashboard.render.com (visionclass-ml service)

### PASO 2: Una vez deployed, Abre la Consola de Render
En Render Dashboard:
1. Click `visionclass-ml` service
2. Click `Logs` tab
3. Busca l√≠neas que digan:

```
‚úÖ [INIT] MediaPipe FaceMesh initialized successfully
```

**O**

```
‚ö†Ô∏è  [INIT] MediaPipe FaceMesh initialization FAILED
```

**Si ves FAILED**: El problema es que MediaPipe no se puede instalar en Render. Ver SOLUCI√ìN A abajo.

### PASO 3: Test Frame Capture
Una vez deployed, una persona abre la app en Render:
1. Login como student
2. Entra a lesson con c√°mara
3. Permite permisos de c√°mara
4. Espera 5 segundos grabando

**En Render logs ML Service, deber√≠a ver**:

Opci√≥n A (SUCCESS):
```
[analyze_frame] üì• Frame recibido: XXXX bytes
[analyze_frame] ‚úÖ Decodificado OK: forma=(480, 640, 3)
[compute_attention] ‚úÖ ROSTRO DETECTADO!
```

Opci√≥n B (Canvas vac√≠o):
```
[analyze_frame] üì• Frame recibido: 500 bytes
[analyze_frame] ‚úÖ Decodificado OK: forma=(480, 640, 3)
[compute_attention] ‚ö†Ô∏è  NO DETECTADO shape=(480, 640, 3) range=[0,0]
```
‚Üí Si ves range=[0,0], **Canvas est√° dark/empty**

Opci√≥n C (MediaPipe no inicializ√≥):
```
[analyze_frame] üì• Frame recibido: 2000 bytes
[compute_attention] ‚ö†Ô∏è  face_mesh_init=False
```
‚Üí Ver SOLUCI√ìN A

---

## üö® SOLUCIONES POR ESCENARIO

### SOLUCI√ìN A: MediaPipe No Inicializ√≥ (face_mesh=None)

**S√≠ntoma**: Logs muestran `face_mesh_init=False` o error "FaceMesh initialization FAILED"

**Root Cause**: 
- Package `mediapipe` no instal√≥ en Render
- O versi√≥n de Python incompatible
- O falta dependencia (protobuf, etc)

**Fix**:

1. **Revisar `ml/requirements.txt`**:
   ```bash
   cat ml/requirements.txt | grep mediapipe
   ```
   Deber√≠a mostrar: `mediapipe>=0.9.0`

2. **Si NO est√°, agregarlo**:
   ```bash
   echo "mediapipe>=0.9.0" >> ml/requirements.txt
   ```

3. **Si YA est√°, fuerza rebuild**:
   - Render Dashboard ‚Üí visionclass-ml
   - Click dropdown menu top-right
   - Select "Trigger deploy"
   - Espera deploy, revisar logs para errores pip

4. **Si sigue fallando**, agregar requirements m√°s espec√≠ficos:
   ```
   mediapipe==0.10.0
   numpy<2.0
   opencv-python==4.8.1.78
   protobuf==3.20.0
   ```

---

### SOLUCI√ìN B: Canvas Est√° Vac√≠o (range=[0,0])

**S√≠ntoma**: Frames llegan con range=[0,0], shape OK pero sin contenido

**Root Cause**:
- Video stream no est√° playing
- Canvas size 0x0
- getUserMedia() fall√≥ silenciosamente

**Fix**:

En `frontend/app/student/course/[courseId]/page.tsx`, en la funci√≥n `requestCamera()`:

```typescript
async function requestCamera() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    if (!videoRef.current) return;
    
    videoRef.current.srcObject = stream;
    
    // DEBUG: Esperar que el video est√© listo
    await new Promise(resolve => {
      videoRef.current!.onloadedmetadata = () => {
        console.log('‚úÖ Video metadata loaded');
        console.log('   Video size:', videoRef.current!.videoWidth, 'x', videoRef.current!.videoHeight);
        videoRef.current!.play().then(() => {
          console.log('‚úÖ Video is now playing');
          resolve(null);
        });
      };
    });
    
    // Verificar canvas est√° ok
    const canvas = canvasRef.current;
    if (canvas.width === 0 || canvas.height === 0) {
      console.error('‚ùå Canvas size is 0! Check canvas element attributes');
      return;
    }
    
    console.log('‚úÖ Canvas size:', canvas.width, 'x', canvas.height);
    cameraActiveRef.current = true;
    
  } catch (e) {
    console.error('‚ùå getUserMedia failed:', e);
  }
}
```

Esto logar√° cuando:
- Video actually est√° playing
- Canvas tiene tama√±o correcto  
- Si falla, te dir√° por qu√©

---

### SOLUCI√ìN C: Logging Muy B√°sico (Quiero Ver EXACTAMENTE Qu√© Env√≠a)

Si necesitas m√°ximo detalle de qu√© trae el frame:

**En `ml/ml_service.py`, en `/analyze/frame` endpoint**:

```python
content = await file.read()
print(f"[DEBUG] Bytes recibidos: {len(content)}")
np_arr = np.frombuffer(content, np.uint8)
image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

if image is None:
    print(f"[DEBUG] ‚ùå cv2.imdecode() devolvi√≥ None!")
else:
    # Calcular statistics
    img_min, img_max = image.min(), image.max()
    is_empty = (img_max - img_min) < 10
    non_zero_pixels = (image > 10).sum()
    
    print(f"[DEBUG] ‚úÖ Imagen decodificada:")
    print(f"   shape: {image.shape}")
    print(f"   dtype: {image.dtype}")
    print(f"   min: {img_min}, max: {img_max}")
    print(f"   empty?: {is_empty}")
    print(f"   non_zero_pixels: {non_zero_pixels} de {image.size}")
    print(f"   mean: {image.mean():.1f}")
```

Esto te mostrar√° EXACTAMENTE qu√© trae el frame.

---

## üìã Checklist de Debugging

```
[ ] 1. Render redeploy√≥ ML Service con nuevos logs
[ ] 2. Abre logs de Render ML Service 
[ ] 3. Busca [INIT] - ¬øinicializ√≥ MediaPipe?
[ ] 4. Un usuario intenta capturar en producci√≥n
[ ] 5. Revisa logs ML para ver qu√© frame lleg√≥:
        - Si range=[0,0] ‚Üí Canvas vac√≠o (SOLUCI√ìN B)
        - Si face_mesh=False ‚Üí MediaPipe no inicializ√≥ (SOLUCI√ìN A)
        - Si ‚úÖ pero face=False ‚Üí MediaPipe no detecta rostro leg√≠timo
          (prueba con imagen mejor iluminada o acerca m√°s)
```

---

## üìû Test Local (SIN Producci√≥n)

Puedes probar localmente si quieres:

```bash
# 1. Start ML Service locally
cd ml
python -m uvicorn ml_service:app --host 0.0.0.0 --port 9000

# 2. En otra terminal, run test
cd ..
python test_ml_service.py

# Ver logs de ML Service - mostrar√°:
# ‚úÖ [INIT] MediaPipe initialized
# üì• Frame received: XXXX bytes
# ‚úÖ Decodificado OK: ...
# ... resultado de face detection
```

---

## üé¨ Pr√≥ximos Pasos

1. **Hoy**: Esperar redeployment de Render (3-5 min)
2. **Cuando est√© live**: Usuario intenta capturar en Render
3. **Monitor**: Revisar logs ML Service para:
   - `[INIT]` messages
   - `frame recibido` y `decodificado`
   - `face=False` o `‚úÖ DETECTADO`
4. **Si falla**: Aplicar soluci√≥n correspondiente (A, B, o C)
5. **Cuando funcione**: Rastrear por cu√°nto tiempo los rostros se detectan en la API

---

## üí° Insights Clave

El hecho de que:
- ‚úÖ Backend recibe requests
- ‚úÖ Frontend env√≠a frames
- ‚ùå Pero NUNCA hay face=True

Significa **definitivamente** uno de estos:
1. MediaPipe = None (no inicializ√≥)
2. image shape / range wrong (frame vac√≠o)
3. imagen demasiado peque√±a/ pobre calidad para detectar

YA HEMOS DESCARTADO:
- ‚úÖ Network connectivity (requests llegan)
- ‚úÖ CORS issues (requests procesa)
- ‚úÖ Frontend permissions (video captura)

**El pr√≥ximo redeployment con logs mejores responder√° cu√°l es.**

---

**Date**: 2026-02-09
**Status**: Debugging phase - Waiting for Render redeployment
